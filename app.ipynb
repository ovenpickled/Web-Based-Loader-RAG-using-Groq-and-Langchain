{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores.cassandra import Cassandra\n",
    "import cassio\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_api_key = os.environ['GROQ_API_KEY']\n",
    "ASTRA_DB_APPLICATION_TOKEN=\"AstraCS:MoSHHhIxBPvcBlSZsDMDXCXM:7928de80ad1f6e930ddea1b068e8e3b899624271efbcd13d2e3d8870dccd6e99\"\n",
    "ASTRA_DB_ID=\"646e76a2-9946-4c52-b024-ef8926e4c3bc\"\n",
    "cassio.init(token=ASTRA_DB_APPLICATION_TOKEN, database_id=ASTRA_DB_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "import bs4\n",
    "\n",
    "loader=WebBaseLoader(web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "                     bs_kwargs=dict(parse_only=bs4.SoupStrainer(\n",
    "                         class_=(\"post-title\",\"post-content\",\"post-header\")\n",
    "\n",
    "                     )))\n",
    "\n",
    "text_documents=loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter= RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "docs=text_splitter.split_documents(text_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import Ollama\n",
    "ollama = Ollama(base_url='http:localhost:4000', model='llama2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OllamaEmbeddings()\n",
    "astra_vector_store = Cassandra(\n",
    "    embedding=embeddings,\n",
    "    table_name=\"web_based_loader\",\n",
    "    session=None,\n",
    "    keyspace=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 66 headlines.\n"
     ]
    }
   ],
   "source": [
    "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
    "astra_vector_store.add_documents(docs)\n",
    "print(\"Inserted %i headlines.\" % len(docs))\n",
    "\n",
    "astra_vector_index = VectorStoreIndexWrapper(vectorstore=astra_vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatGroq(groq_api_key=groq_api_key,\n",
    "         model_name=\"mixtral-8x7b-32768\")\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Answer the following question based only on the provided context. \n",
    "Think step by step before providing a detailed answer. \n",
    "I will tip you $1000 if the user finds the answer helpful. \n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Question: {input}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It seems like you're looking for information and guidance related to various resources and papers about language models, tool usage, and file naming conventions. I'll first address the goals, constraints, and resources you provided, and then I'll give a brief overview of the relevant papers and file naming conventions.\\n\\nGoals, constraints, and resources:\\n1. Your goals are not explicitly stated, so I will provide general information that could be helpful.\\n2. The constraints include a 4000-word limit, no user assistance, using specific commands, and using subprocesses for long-running commands.\\n3. Resources include internet access, long-term memory management, GPT-3.5 agents for simple tasks, and file output.\\n\\nPapers and overviews:\\n1. Schick et al. (2023) - Toolformer: This paper discusses language models teaching themselves to use tools. This could be relevant if your goal is to create a model that can use tools or APIs effectively.\\n2. Li et al. (2023) - API-Bank: This paper introduces a benchmark for tool-augmented language models, which could be useful if you're looking to compare different models that use tools or APIs.\\n3. Shen et al. (2023) - HuggingGPT: This paper presents a way to solve AI tasks with ChatGPT and HuggingFace models. This could be helpful if you're interested in using pre-trained models for specific tasks.\\n4. Bran et al. (2023) - ChemCrow: This paper discusses augmenting language models with chemistry tools. This could be relevant if your goal is to work with domain-specific tools or APIs.\\n5. Boiko et al. (2023) - Emergent autonomous scientific research capabilities: This paper explores the emergent capabilities of large language models in conducting scientific research. This could be useful if your goal is to understand the current state of the art in AI research.\\n6. Park et al. (2023) - Generative Agents: This paper introduces interactive simulacra of human behavior. This could be relevant if your goal is to create more engaging or human-like agents.\\n\\nFile naming conventions:\\nFor Python, you should follow the PEP8 style guide, which recommends using lowercase letters with words separated by underscores as necessary, e.g., `my_module.py`. For NodeJS, you should follow the official style guide, which recommends using lowercase letters with words separated by dashes as necessary, e.g., `my-module.js`.\\n\\nFor both languages, it's a good practice to create a `requirements.txt` or `package.json` file to manage dependencies.\\n\\nIn summary, I've provided information related to the papers you mentioned, as well as general guidance on file naming conventions for Python and NodeJS. If you have specific goals, please provide them so I can give more targeted advice.\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "astra_vector_index.query(\"Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique\",llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "retriever=astra_vector_store.as_retriever()\n",
    "document_chain=create_stuff_documents_chain(llm,prompt)\n",
    "retrieval_chain=create_retrieval_chain(retriever,document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique',\n",
       " 'context': [Document(page_content='[13] Schick et al. “Toolformer: Language Models Can Teach Themselves to Use Tools.” arXiv preprint arXiv:2302.04761 (2023).\\n[14] Weaviate Blog. Why is Vector Search so fast? Sep 13, 2022.\\n[15] Li et al. “API-Bank: A Benchmark for Tool-Augmented LLMs” arXiv preprint arXiv:2304.08244 (2023).\\n[16] Shen et al. “HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace” arXiv preprint arXiv:2303.17580 (2023).\\n[17] Bran et al. “ChemCrow: Augmenting large-language models with chemistry tools.” arXiv preprint arXiv:2304.05376 (2023).\\n[18] Boiko et al. “Emergent autonomous scientific research capabilities of large language models.” arXiv preprint arXiv:2304.05332 (2023).\\n[19] Joon Sung Park, et al. “Generative Agents: Interactive Simulacra of Human Behavior.” arXiv preprint arXiv:2304.03442 (2023).\\n[20] AutoGPT. https://github.com/Significant-Gravitas/Auto-GPT\\n[21] GPT-Engineer. https://github.com/AntonOsika/gpt-engineer', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}),\n",
       "  Document(page_content='GOALS:\\n\\n1. {{user-provided goal 1}}\\n2. {{user-provided goal 2}}\\n3. ...\\n4. ...\\n5. ...\\n\\nConstraints:\\n1. ~4000 word limit for short term memory. Your short term memory is short, so immediately save important information to files.\\n2. If you are unsure how you previously did something or want to recall past events, thinking about similar events will help you remember.\\n3. No user assistance\\n4. Exclusively use the commands listed in double quotes e.g. \"command name\"\\n5. Use subprocesses for commands that will not terminate within a few minutes', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}),\n",
       "  Document(page_content='for the code\\'s language, and CODE is the code:\\\\n\\\\nFILENAME\\\\n```LANG\\\\nCODE\\\\n```\\\\n\\\\nYou will start with the \\\\\"entrypoint\\\\\" file, then go to the ones that are imported by that file, and so on.\\\\nPlease note that the code should be fully functional. No placeholders.\\\\n\\\\nFollow a language and framework appropriate best practice file naming convention.\\\\nMake sure that files contain all imports, types etc. Make sure that code in different files are compatible with each other.\\\\nEnsure to implement all code, if you are unsure, write a plausible implementation.\\\\nInclude module dependency or package manager dependency definition file.\\\\nBefore you finish, double check that all parts of the architecture is present in the files.\\\\n\\\\nUseful to know:\\\\nYou almost always put different classes in different files.\\\\nFor Python, you always create an appropriate requirements.txt file.\\\\nFor NodeJS, you always create an appropriate package.json file.\\\\nYou always add a comment briefly describing the purpose of', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}),\n",
       "  Document(page_content='Resources:\\n1. Internet access for searches and information gathering.\\n2. Long Term memory management.\\n3. GPT-3.5 powered Agents for delegation of simple tasks.\\n4. File output.\\n\\nPerformance Evaluation:\\n1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\\n2. Constructively self-criticize your big-picture behavior constantly.\\n3. Reflect on past decisions and strategies to refine your approach.\\n4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'})],\n",
       " 'answer': \"To determine if chain of thought (CoT) has become a standard prompting technique, I will first clarify what CoT is and then examine the given resources to see if it is mentioned or used.\\n\\nChain of thought (CoT) is a prompting technique where a language model is encouraged to generate a series of intermediate steps or thoughts before producing the final answer. This technique aims to improve the model's problem-solving abilities and provide more insight into its decision-making process. (Note: Wei et al. 2022 is not part of the provided resources, so I cannot directly reference their work.)\\n\\nNow, I will analyze the given resources:\\n\\n1. [13] Schick et al. “Toolformer: Language Models Can Teach Themselves to Use Tools.” (2023): This paper presents a method for teaching language models to use tools, but it does not mention or use CoT as a prompting technique.\\n2. [14] Weaviate Blog. “Why is Vector Search so fast?” (2022): This blog post discusses vector search but does not mention or use CoT.\\n3. [15] Li et al. “API-Bank: A Benchmark for Tool-Augmented LLMs” (2023): This paper introduces a benchmark for tool-augmented language models, but it does not mention or use CoT.\\n4. [16] Shen et al. “HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace” (2023): This paper describes a framework for solving AI tasks using various models, including ChatGPT, but it does not mention or use CoT.\\n5. [17] Bran et al. “ChemCrow: Augmenting large-language models with chemistry tools.” (2023): This paper explores augmenting language models with chemistry tools, but it does not mention or use CoT.\\n6. [18] Boiko et al. “Emergent autonomous scientific research capabilities of large language models.” (2023): This paper discusses the emergent capabilities of language models in scientific research, but it does not mention or use CoT.\\n7. [19] Park, J. S., et al. “Generative Agents: Interactive Simulacra of Human Behavior.” (2023): This paper introduces generative agents for interactive simulations, but it does not mention or use CoT.\\n8. [20] AutoGPT: This GitHub repository contains code for AutoGPT, but it does not mention or use CoT.\\n9. [21] GPT-Engineer: This GitHub repository contains code for GPT-Engineer, but it does not mention or use CoT.\\n\\nBased on the provided resources, I cannot conclude that CoT has become a standard prompting technique, as it is not mentioned or used in any of the resources. However, this does not necessarily mean that CoT is not a standard technique, as the resources might not be representative of the entire field.\"}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=retrieval_chain.invoke({\"input\":\"Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"To determine if chain of thought (CoT) has become a standard prompting technique, I will first clarify what CoT is and then examine the given resources to see if it is mentioned or used.\\n\\nChain of thought (CoT) is a prompting technique where a language model is encouraged to generate a series of intermediate steps or thoughts before producing the final answer. This technique aims to improve the model's problem-solving abilities and provide more insight into its decision-making process. (Note: Wei et al. 2022 is not part of the provided resources, so I cannot directly reference their work.)\\n\\nNow, I will analyze the given resources:\\n\\n1. [13] Schick et al. “Toolformer: Language Models Can Teach Themselves to Use Tools.” (2023): This paper presents a method for teaching language models to use tools, but it does not mention or use CoT as a prompting technique.\\n2. [14] Weaviate Blog. “Why is Vector Search so fast?” (2022): This blog post discusses vector search but does not mention or use CoT.\\n3. [15] Li et al. “API-Bank: A Benchmark for Tool-Augmented LLMs” (2023): This paper introduces a benchmark for tool-augmented language models, but it does not mention or use CoT.\\n4. [16] Shen et al. “HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace” (2023): This paper describes a framework for solving AI tasks using various models, including ChatGPT, but it does not mention or use CoT.\\n5. [17] Bran et al. “ChemCrow: Augmenting large-language models with chemistry tools.” (2023): This paper explores augmenting language models with chemistry tools, but it does not mention or use CoT.\\n6. [18] Boiko et al. “Emergent autonomous scientific research capabilities of large language models.” (2023): This paper discusses the emergent capabilities of language models in scientific research, but it does not mention or use CoT.\\n7. [19] Park, J. S., et al. “Generative Agents: Interactive Simulacra of Human Behavior.” (2023): This paper introduces generative agents for interactive simulations, but it does not mention or use CoT.\\n8. [20] AutoGPT: This GitHub repository contains code for AutoGPT, but it does not mention or use CoT.\\n9. [21] GPT-Engineer: This GitHub repository contains code for GPT-Engineer, but it does not mention or use CoT.\\n\\nBased on the provided resources, I cannot conclude that CoT has become a standard prompting technique, as it is not mentioned or used in any of the resources. However, this does not necessarily mean that CoT is not a standard technique, as the resources might not be representative of the entire field.\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"answer\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
